{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from src.table_extraction_tools.crosstab_normalization import normalize_crosstab\n",
    "\n",
    "# Import environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Define output directory\n",
    "output_dir = os.getenv(\"OUTPUT_DIR\")\n",
    "\n",
    "# Open PDF file to extract tables (load path from dotenv)\n",
    "pdf_path = os.getenv(\"PDF_PATH\")\n",
    "pdf = pdfplumber.open(pdf_path)\n",
    "\n",
    "# Define pages to skip\n",
    "skip_pages = [1, 2, 69, 100, 111, 122, 125, 134, 156, 167, 170, 174, 201, 228, 238, 269, 271, 273, 282]\n",
    "\n",
    "# Configuration lookup for each table\n",
    "table_config = {\n",
    "    \"A-1\": 1, # 3\n",
    "    \"A-2\": 1, # 70\n",
    "    \"A-3\": 2, # 101\n",
    "    \"A-4\": 2, # 112\n",
    "    \"A-5\": 1, # 123\n",
    "    \"A-6\": 2, # 126\n",
    "    \"A-7\": 1, # 135\n",
    "    \"A-8\": 1, # 157\n",
    "    \"A-9\": 3, # 168\n",
    "    \"A-10\": 2, # 171\n",
    "    \"A-11\": 4, # 175\n",
    "    \"A-12\": [4,5], # 202\n",
    "    \"A-13\": [4,6,6], # 229\n",
    "    \"A-14\": 4, # 239\n",
    "    \"A-15\": 7, # 270\n",
    "    \"A-16\": 3, # 272\n",
    "    \"A-17\": 2, # 274\n",
    "    \"A-18\": 8 # 283\n",
    "}\n",
    "\n",
    "# Define the settings for normalizing the table\n",
    "normalization_settings = {\n",
    "    1: {\"header_row_index\":5,\"id_columns\":4,\"data_column_names\":4},\n",
    "    2: {\"header_row_index\":4,\"id_columns\":4,\"data_column_names\":4},\n",
    "    3: {\"header_row_index\":5,\"id_columns\":2,\"data_column_names\":1},\n",
    "    4: {\"header_row_index\":5,\"id_columns\":5,\"data_column_names\":4},\n",
    "    5: {\"header_row_index\":4,\"id_columns\":5,\"data_column_names\":4},\n",
    "    6: {\"header_row_index\":0,\"id_columns\":5,\"data_column_names\":4},\n",
    "    7: {\"header_row_index\":4,\"id_columns\":2,\"data_column_names\":1},\n",
    "    8: {\"header_row_index\":4,\"id_columns\":1,\"data_column_names\":1}\n",
    "}\n",
    "\n",
    "def clean_names(names):\n",
    "    # Remove trailing leading and extra whitespace, convert to lowercase, replace spaces and hyphens with underscores, and remove all other characters\n",
    "    names = names.str.strip()\n",
    "    names = names.str.lower()\n",
    "    names = names.str.replace(r\"[\\/_-]+\", \" \", regex=True)\n",
    "    names = names.str.replace(r\"[^a-z\\s]\", \"\", regex=True)\n",
    "    names = names.str.strip()\n",
    "    names = names.str.replace(r\"[\\s]+\", \"_\", regex=True)\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping page 1...\n",
      "Skipping page 2...\n",
      "Extracting table A-1 part 1 from page 3...\n",
      "Extracting table A-1 part 2 from page 4...\n",
      "Extracting table A-1 part 3 from page 5...\n",
      "Extracting table A-1 part 4 from page 6...\n",
      "Extracting table A-1 part 5 from page 7...\n",
      "Extracting table A-1 part 6 from page 8...\n",
      "Extracting table A-1 part 7 from page 9...\n",
      "Extracting table A-1 part 8 from page 10...\n",
      "Extracting table A-1 part 9 from page 11...\n",
      "Extracting table A-1 part 10 from page 12...\n",
      "Extracting table A-1 part 11 from page 13...\n",
      "Extracting table A-1 part 12 from page 14...\n",
      "Extracting table A-1 part 13 from page 15...\n",
      "Extracting table A-1 part 14 from page 16...\n",
      "Extracting table A-1 part 15 from page 17...\n",
      "Extracting table A-1 part 16 from page 18...\n",
      "Extracting table A-1 part 17 from page 19...\n",
      "Extracting table A-1 part 18 from page 20...\n",
      "Extracting table A-1 part 19 from page 21...\n",
      "Extracting table A-1 part 20 from page 22...\n",
      "Extracting table A-1 part 21 from page 23...\n",
      "Extracting table A-1 part 22 from page 24...\n",
      "Extracting table A-1 part 23 from page 25...\n",
      "Extracting table A-1 part 24 from page 26...\n",
      "Extracting table A-1 part 25 from page 27...\n",
      "Extracting table A-1 part 26 from page 28...\n",
      "Extracting table A-1 part 27 from page 29...\n",
      "Extracting table A-1 part 28 from page 30...\n",
      "Extracting table A-1 part 29 from page 31...\n",
      "Extracting table A-1 part 30 from page 32...\n",
      "Extracting table A-1 part 31 from page 33...\n",
      "Extracting table A-1 part 32 from page 34...\n",
      "Extracting table A-1 part 33 from page 35...\n",
      "Extracting table A-1 part 34 from page 36...\n",
      "Extracting table A-1 part 35 from page 37...\n",
      "Extracting table A-1 part 36 from page 38...\n",
      "Extracting table A-1 part 37 from page 39...\n",
      "Extracting table A-1 part 38 from page 40...\n",
      "Extracting table A-1 part 39 from page 41...\n",
      "Extracting table A-1 part 40 from page 42...\n",
      "Extracting table A-1 part 41 from page 43...\n",
      "Extracting table A-1 part 42 from page 44...\n",
      "Extracting table A-1 part 43 from page 45...\n",
      "Extracting table A-1 part 44 from page 46...\n",
      "Extracting table A-1 part 45 from page 47...\n",
      "Extracting table A-1 part 46 from page 48...\n",
      "Extracting table A-1 part 47 from page 49...\n",
      "Extracting table A-1 part 48 from page 50...\n",
      "Extracting table A-1 part 49 from page 51...\n",
      "Extracting table A-1 part 50 from page 52...\n",
      "Extracting table A-1 part 51 from page 53...\n",
      "Extracting table A-1 part 52 from page 54...\n",
      "Extracting table A-1 part 53 from page 55...\n",
      "Extracting table A-1 part 54 from page 56...\n",
      "Extracting table A-1 part 55 from page 57...\n",
      "Extracting table A-1 part 56 from page 58...\n",
      "Extracting table A-1 part 57 from page 59...\n",
      "Extracting table A-1 part 58 from page 60...\n",
      "Extracting table A-1 part 59 from page 61...\n",
      "Extracting table A-1 part 60 from page 62...\n",
      "Extracting table A-1 part 61 from page 63...\n",
      "Extracting table A-1 part 62 from page 64...\n",
      "Extracting table A-1 part 63 from page 65...\n",
      "Extracting table A-1 part 64 from page 66...\n",
      "Extracting table A-1 part 65 from page 67...\n",
      "Extracting table A-1 part 66 from page 68...\n",
      "Skipping page 69...\n",
      "Extracting table A-2 part 1 from page 70...\n",
      "Extracting table A-2 part 2 from page 71...\n",
      "Extracting table A-2 part 3 from page 72...\n",
      "Extracting table A-2 part 4 from page 73...\n",
      "Extracting table A-2 part 5 from page 74...\n",
      "Extracting table A-2 part 6 from page 75...\n",
      "Extracting table A-2 part 7 from page 76...\n",
      "Extracting table A-2 part 8 from page 77...\n",
      "Extracting table A-2 part 9 from page 78...\n",
      "Extracting table A-2 part 10 from page 79...\n",
      "Extracting table A-2 part 11 from page 80...\n",
      "Extracting table A-2 part 12 from page 81...\n",
      "Extracting table A-2 part 13 from page 82...\n",
      "Extracting table A-2 part 14 from page 83...\n",
      "Extracting table A-2 part 15 from page 84...\n",
      "Extracting table A-2 part 16 from page 85...\n",
      "Extracting table A-2 part 17 from page 86...\n",
      "Extracting table A-2 part 18 from page 87...\n",
      "Extracting table A-2 part 19 from page 88...\n",
      "Extracting table A-2 part 20 from page 89...\n",
      "Extracting table A-2 part 21 from page 90...\n",
      "Extracting table A-2 part 22 from page 91...\n",
      "Extracting table A-2 part 23 from page 92...\n",
      "Extracting table A-2 part 24 from page 93...\n",
      "Extracting table A-2 part 25 from page 94...\n",
      "Extracting table A-2 part 26 from page 95...\n",
      "Extracting table A-2 part 27 from page 96...\n",
      "Extracting table A-2 part 28 from page 97...\n",
      "Extracting table A-2 part 29 from page 98...\n",
      "Extracting table A-2 part 30 from page 99...\n",
      "Skipping page 100...\n",
      "Extracting table A-3 part 1 from page 101...\n",
      "Extracting table A-3 part 2 from page 102...\n",
      "Extracting table A-3 part 3 from page 103...\n",
      "Extracting table A-3 part 4 from page 104...\n",
      "Extracting table A-3 part 5 from page 105...\n",
      "Extracting table A-3 part 6 from page 106...\n",
      "Extracting table A-3 part 7 from page 107...\n",
      "Extracting table A-3 part 8 from page 108...\n",
      "Extracting table A-3 part 9 from page 109...\n",
      "Extracting table A-3 part 10 from page 110...\n",
      "Skipping page 111...\n",
      "Extracting table A-4 part 1 from page 112...\n",
      "Extracting table A-4 part 2 from page 113...\n",
      "Extracting table A-4 part 3 from page 114...\n",
      "Extracting table A-4 part 4 from page 115...\n",
      "Extracting table A-4 part 5 from page 116...\n",
      "Extracting table A-4 part 6 from page 117...\n",
      "Extracting table A-4 part 7 from page 118...\n",
      "Extracting table A-4 part 8 from page 119...\n",
      "Extracting table A-4 part 9 from page 120...\n",
      "Extracting table A-4 part 10 from page 121...\n",
      "Skipping page 122...\n",
      "Extracting table A-5 part 1 from page 123...\n",
      "Extracting table A-5 part 2 from page 124...\n",
      "Skipping page 125...\n",
      "Extracting table A-6 part 1 from page 126...\n",
      "Extracting table A-6 part 2 from page 127...\n",
      "Extracting table A-6 part 3 from page 128...\n",
      "Extracting table A-6 part 4 from page 129...\n",
      "Extracting table A-6 part 5 from page 130...\n",
      "Extracting table A-6 part 6 from page 131...\n",
      "Extracting table A-6 part 7 from page 132...\n",
      "Extracting table A-6 part 8 from page 133...\n",
      "Skipping page 134...\n",
      "Extracting table A-7 part 1 from page 135...\n",
      "Extracting table A-7 part 2 from page 136...\n",
      "Extracting table A-7 part 3 from page 137...\n",
      "Extracting table A-7 part 4 from page 138...\n",
      "Extracting table A-7 part 5 from page 139...\n",
      "Extracting table A-7 part 6 from page 140...\n",
      "Extracting table A-7 part 7 from page 141...\n",
      "Extracting table A-7 part 8 from page 142...\n",
      "Extracting table A-7 part 9 from page 143...\n",
      "Extracting table A-7 part 10 from page 144...\n",
      "Extracting table A-7 part 11 from page 145...\n",
      "Extracting table A-7 part 12 from page 146...\n",
      "Extracting table A-7 part 13 from page 147...\n",
      "Extracting table A-7 part 14 from page 148...\n",
      "Extracting table A-7 part 15 from page 149...\n",
      "Extracting table A-7 part 16 from page 150...\n",
      "Extracting table A-7 part 17 from page 151...\n",
      "Extracting table A-7 part 18 from page 152...\n",
      "Extracting table A-7 part 19 from page 153...\n",
      "Extracting table A-7 part 20 from page 154...\n",
      "Extracting table A-7 part 21 from page 155...\n",
      "Skipping page 156...\n",
      "Extracting table A-8 part 1 from page 157...\n",
      "Extracting table A-8 part 2 from page 158...\n",
      "Extracting table A-8 part 3 from page 159...\n",
      "Extracting table A-8 part 4 from page 160...\n",
      "Extracting table A-8 part 5 from page 161...\n",
      "Extracting table A-8 part 6 from page 162...\n",
      "Extracting table A-8 part 7 from page 163...\n",
      "Extracting table A-8 part 8 from page 164...\n",
      "Extracting table A-8 part 9 from page 165...\n",
      "Extracting table A-8 part 10 from page 166...\n",
      "Skipping page 167...\n",
      "Extracting table A-9 part 1 from page 168...\n",
      "Extracting table A-9 part 2 from page 169...\n",
      "Skipping page 170...\n",
      "Extracting table A-10 part 1 from page 171...\n",
      "Extracting table A-10 part 2 from page 172...\n",
      "Extracting table A-10 part 3 from page 173...\n",
      "Skipping page 174...\n",
      "Extracting table A-11 part 1 from page 175...\n",
      "Extracting table A-11 part 2 from page 176...\n",
      "Extracting table A-11 part 3 from page 177...\n",
      "Extracting table A-11 part 4 from page 178...\n",
      "Extracting table A-11 part 5 from page 179...\n",
      "Extracting table A-11 part 6 from page 180...\n",
      "Extracting table A-11 part 7 from page 181...\n",
      "Extracting table A-11 part 8 from page 182...\n",
      "Extracting table A-11 part 9 from page 183...\n",
      "Extracting table A-11 part 10 from page 184...\n",
      "Extracting table A-11 part 11 from page 185...\n",
      "Extracting table A-11 part 12 from page 186...\n",
      "Extracting table A-11 part 13 from page 187...\n",
      "Extracting table A-11 part 14 from page 188...\n",
      "Extracting table A-11 part 15 from page 189...\n",
      "Extracting table A-11 part 16 from page 190...\n",
      "Extracting table A-11 part 17 from page 191...\n",
      "Extracting table A-11 part 18 from page 192...\n",
      "Extracting table A-11 part 19 from page 193...\n",
      "Extracting table A-11 part 20 from page 194...\n",
      "Extracting table A-11 part 21 from page 195...\n",
      "Extracting table A-11 part 22 from page 196...\n",
      "Extracting table A-11 part 23 from page 197...\n",
      "Extracting table A-11 part 24 from page 198...\n",
      "Extracting table A-11 part 25 from page 199...\n",
      "Extracting table A-11 part 26 from page 200...\n",
      "Skipping page 201...\n",
      "Extracting table A-12 part 1 from page 202...\n",
      "Extracting table A-12 part 2 from page 203...\n",
      "Extracting table A-12 part 3 from page 204...\n",
      "Extracting table A-12 part 4 from page 205...\n",
      "Extracting table A-12 part 5 from page 206...\n",
      "Extracting table A-12 part 6 from page 207...\n",
      "Extracting table A-12 part 7 from page 208...\n",
      "Extracting table A-12 part 8 from page 209...\n",
      "Extracting table A-12 part 9 from page 210...\n",
      "Extracting table A-12 part 10 from page 211...\n",
      "Extracting table A-12 part 11 from page 212...\n",
      "Extracting table A-12 part 12 from page 213...\n",
      "Extracting table A-12 part 13 from page 214...\n",
      "Extracting table A-12 part 14 from page 215...\n",
      "Extracting table A-12 part 15 from page 216...\n",
      "Extracting table A-12 part 16 from page 217...\n",
      "Extracting table A-12 part 17 from page 218...\n",
      "Extracting table A-12 part 18 from page 219...\n",
      "Extracting table A-12 part 19 from page 220...\n",
      "Extracting table A-12 part 20 from page 221...\n",
      "Extracting table A-12 part 21 from page 222...\n",
      "Extracting table A-12 part 22 from page 223...\n",
      "Extracting table A-12 part 23 from page 224...\n",
      "Extracting table A-12 part 24 from page 225...\n",
      "Extracting table A-12 part 25 from page 226...\n",
      "Extracting table A-12 part 26 from page 227...\n",
      "Skipping page 228...\n",
      "Extracting table A-13 part 1 from page 229...\n",
      "Extracting table A-13 part 2 from page 230...\n",
      "Extracting table A-13 part 3 from page 231...\n",
      "Extracting table A-13 part 4 from page 232...\n",
      "Extracting table A-13 part 5 from page 233...\n",
      "Extracting table A-13 part 6 from page 234...\n",
      "Extracting table A-13 part 7 from page 235...\n",
      "Extracting table A-13 part 8 from page 236...\n",
      "Extracting table A-13 part 9 from page 237...\n",
      "Skipping page 238...\n",
      "Extracting table A-14 part 1 from page 239...\n",
      "Extracting table A-14 part 2 from page 240...\n",
      "Extracting table A-14 part 3 from page 241...\n",
      "Extracting table A-14 part 4 from page 242...\n",
      "Extracting table A-14 part 5 from page 243...\n",
      "Extracting table A-14 part 6 from page 244...\n",
      "Extracting table A-14 part 7 from page 245...\n",
      "Extracting table A-14 part 8 from page 246...\n",
      "Extracting table A-14 part 9 from page 247...\n",
      "Extracting table A-14 part 10 from page 248...\n",
      "Extracting table A-14 part 11 from page 249...\n",
      "Extracting table A-14 part 12 from page 250...\n",
      "Extracting table A-14 part 13 from page 251...\n",
      "Extracting table A-14 part 14 from page 252...\n",
      "Extracting table A-14 part 15 from page 253...\n",
      "Extracting table A-14 part 16 from page 254...\n",
      "Extracting table A-14 part 17 from page 255...\n",
      "Extracting table A-14 part 18 from page 256...\n",
      "Extracting table A-14 part 19 from page 257...\n",
      "Extracting table A-14 part 20 from page 258...\n",
      "Extracting table A-14 part 21 from page 259...\n",
      "Extracting table A-14 part 22 from page 260...\n",
      "Extracting table A-14 part 23 from page 261...\n",
      "Extracting table A-14 part 24 from page 262...\n",
      "Extracting table A-14 part 25 from page 263...\n",
      "Extracting table A-14 part 26 from page 264...\n",
      "Extracting table A-14 part 27 from page 265...\n",
      "Extracting table A-14 part 28 from page 266...\n",
      "Extracting table A-14 part 29 from page 267...\n",
      "Extracting table A-14 part 30 from page 268...\n",
      "Skipping page 269...\n",
      "Extracting table A-15 part 1 from page 270...\n",
      "Skipping page 271...\n",
      "Extracting table A-16 part 1 from page 272...\n",
      "Skipping page 273...\n",
      "Extracting table A-17 part 1 from page 274...\n",
      "Extracting table A-17 part 2 from page 275...\n",
      "Extracting table A-17 part 3 from page 276...\n",
      "Extracting table A-17 part 4 from page 277...\n",
      "Extracting table A-17 part 5 from page 278...\n",
      "Extracting table A-17 part 6 from page 279...\n",
      "Extracting table A-17 part 7 from page 280...\n",
      "Extracting table A-17 part 8 from page 281...\n",
      "Skipping page 282...\n",
      "Extracting table A-18 part 1 from page 283...\n",
      "Extracting table A-18 part 2 from page 284...\n",
      "Extracting table A-18 part 3 from page 285...\n",
      "Extracting table A-18 part 4 from page 286...\n",
      "Extracting table A-18 part 5 from page 287...\n",
      "Extracting table A-18 part 6 from page 288...\n",
      "Extracting table A-18 part 7 from page 289...\n",
      "Extracting table A-18 part 8 from page 290...\n",
      "Extracting table A-18 part 9 from page 291...\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list\n",
    "all_tables = []\n",
    "table_numbers = []\n",
    "table_count = 0\n",
    "\n",
    "# Initialize the last table number, headers, \n",
    "last_table_number = \"\"\n",
    "last_table_headers = []\n",
    "last_table_config = {}\n",
    "\n",
    "# Loop through each page in the PDF\n",
    "for page_num in range(1, 292):\n",
    "    # Skip pages that don't contain tables\n",
    "    if page_num in skip_pages:\n",
    "        print(f\"Skipping page {page_num}...\")\n",
    "        continue\n",
    "    \n",
    "    # Extract the page\n",
    "    p0 = pdf.pages[page_num-1]\n",
    "    # im = p0.to_image(resolution=150)\n",
    "    \n",
    "    # Extract all text from the page and print it\n",
    "    text = p0.extract_text()\n",
    "\n",
    "    # Extract table title, sub-title, and site name as first three lines of text\n",
    "    title = text.split(\"\\n\")[0]\n",
    "    subtitle = text.split(\"\\n\")[1]\n",
    "    site_name = text.split(\"\\n\")[2]\n",
    "    # print([title, subtitle, site_name])\n",
    "    \n",
    "    # Get table number from title and set normalization settings\n",
    "    table_number = re.findall(r'^[A-Z]+\\s([A-Z]-\\d+)', title)[0]\n",
    "    if table_number == last_table_number:\n",
    "        table_page_count = table_page_count + 1\n",
    "    else:\n",
    "        table_numbers = table_numbers + [table_number]\n",
    "        table_page_count = 1\n",
    "        table_count = table_count + 1\n",
    "        all_tables.append(pd.DataFrame())\n",
    "    \n",
    "    # Print the table number and page number\n",
    "    print(f\"Extracting table {table_number} part {table_page_count} from page {page_num}...\")\n",
    "    \n",
    "    # Set normalization settings\n",
    "    table_config_number = table_config[table_number]\n",
    "    \n",
    "    # If table_config_number is an integer, use that as the index for normalization_settings\n",
    "    if isinstance(table_config_number, int):\n",
    "        normalize_settings = normalization_settings[table_config_number].copy()\n",
    "    # If table_config_number is a list, use the modulous of the table_page_count to get the index for normalization_settings based on the length of the list\n",
    "    # (e.g. if table_config_number is [5,6] and table_page_count is 1, use 5; if table_page_count is 2, use 6; if table_page_count is 3, use 5; etc.)\n",
    "    elif isinstance(table_config_number, list):\n",
    "        num_config = len(table_config_number)\n",
    "        config_number = table_config_number[(table_page_count-1) % num_config]\n",
    "        normalize_settings = normalization_settings[config_number].copy()\n",
    "    \n",
    "    # Get the header row index from the normalization settings\n",
    "    n = normalize_settings[\"header_row_index\"]\n",
    "    m = normalize_settings[\"id_columns\"]\n",
    "    \n",
    "    # Define table settings to find the upper table boundaries\n",
    "    if (table_number == \"A-14\"):\n",
    "        table_settings={\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "        }\n",
    "    else:\n",
    "        table_settings={\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"text\"\n",
    "        }\n",
    "\n",
    "    # Find the table, extract title and headers, and display them\n",
    "    tables = p0.find_tables(table_settings)\n",
    "    \n",
    "    # Loop through each table on the page\n",
    "    for table in tables:\n",
    "        # Obtain the bounding box of the table and crop the page to the table\n",
    "        bounding_box = table.bbox\n",
    "        bounding_box = (0, bounding_box[1], p0.width, bounding_box[3])\n",
    "        p1 = p0.crop(bounding_box)\n",
    "        # im_cropped = p1.to_image()\n",
    "        \n",
    "        # Define table settings to find the table headers and vertical lines\n",
    "        table_settings={\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"text\",\n",
    "            \"intersection_x_tolerance\": 15\n",
    "        }\n",
    "\n",
    "        # Find the table and remove empty rows\n",
    "        table_cropped = p1.find_table(table_settings)\n",
    "        extracted_data = table_cropped.extract()\n",
    "        # im_cropped.reset().debug_tablefinder(table_settings)\n",
    "\n",
    "        # Get index of empty rows and remove them from extracted data\n",
    "        empty_rows = [i for i, row in enumerate(extracted_data) if not any(row)]\n",
    "        extracted_data = [row for row in extracted_data if any(row)]\n",
    "        extracted_rows = table_cropped.rows\n",
    "        extracted_rows = [row for i, row in enumerate(extracted_rows) if i not in empty_rows]\n",
    "        \n",
    "        # Remove empty rows and extract headers as first n rows\n",
    "        extracted_headers = extracted_data[:n]\n",
    "        \n",
    "        # Extract the vertical lines from the nth row and add the right boundary of the table\n",
    "        cell_data = extracted_rows[n].cells\n",
    "        vertical_lines = [cell[0] for cell in cell_data]\n",
    "        vertical_lines.append(table_cropped.bbox[2])\n",
    "\n",
    "        # Define table settings with explicit vertical lines\n",
    "        table_settings={\n",
    "            \"vertical_strategy\": \"explicit\",\n",
    "            \"explicit_vertical_lines\": vertical_lines,\n",
    "            \"horizontal_strategy\": \"text\",\n",
    "            \"intersection_x_tolerance\": 15\n",
    "        }\n",
    "        \n",
    "        # Extract table from cropped page with updated table settings and remove empty rows\n",
    "        extracted_table = p1.extract_table(table_settings)\n",
    "        extracted_table = [row for row in extracted_table if any(row)]\n",
    "        # im_cropped.reset().debug_tablefinder(table_settings)\n",
    "\n",
    "        # Combine text from rows n and n+1 by concatenating the strings vertically and adding a space if table_number not \"A-9\", \"A-15\", or \"A-16\"\n",
    "        if (table_number not in [\"A-9\", \"A-15\", \"A-16\"]):\n",
    "            extracted_table[n] = [i + \" \" + j for i, j in zip(extracted_table[n], extracted_table[n+1])]\n",
    "            extracted_table.pop(n+1)\n",
    "\n",
    "        # Remove the first n rows and add headers to the table by concatenating the two dataframes if n > 0\n",
    "        if (n > 0):\n",
    "            extracted_table = extracted_table[n:]\n",
    "            extracted_table = extracted_headers + extracted_table\n",
    "            last_table_headers = extracted_headers\n",
    "            last_table_config = normalize_settings.copy()\n",
    "            \n",
    "        # If n = 0, add the last table headers to the table and use the last table's header row index and data column headers\n",
    "        elif (n == 0):\n",
    "            extracted_table = last_table_headers + extracted_table\n",
    "            normalize_settings['header_row_index'] = last_table_config['header_row_index']\n",
    "            n = normalize_settings[\"header_row_index\"]\n",
    "        \n",
    "        # If the value in the first row and column is NaN, replace it with \"Location ID:\" and replace the rest of the row with empty strings\n",
    "        if pd.isna(extracted_table[0][0]):\n",
    "            extracted_table[0][0] = \"Location ID:\"\n",
    "            extracted_table[0][1:m] = [\"\" for i in range(1,m)]\n",
    "        \n",
    "        # Concatenate the strings vertically and add a space for each column\n",
    "        concatenated_rows = []\n",
    "        concatenated_row = \"\"\n",
    "        \n",
    "        # Loop through the cols/rows to concatenate\n",
    "        for col_index in range(1,m):\n",
    "            for row_index in range(0,n):\n",
    "                concatenated_row = concatenated_row + \" \" + extracted_table[row_index][col_index]\n",
    "            concatenated_rows.append(concatenated_row)\n",
    "            concatenated_row = \"\"\n",
    "        \n",
    "        # Remove leading/trailing/extra spaces from the concatenated rows\n",
    "        concatenated_rows = [row.strip() for row in concatenated_rows]\n",
    "        \n",
    "        # Add concatenated rows to the table\n",
    "        extracted_table[n][1:m] = concatenated_rows\n",
    "        \n",
    "        # Add analyte header to the table if empty\n",
    "        if extracted_table[n][0] in [\"\", \" \"]:\n",
    "            extracted_table[n][0] = \"Analyte\"\n",
    "        \n",
    "        # Convert the table to a Pandas DataFrame and normalize the table\n",
    "        normalized_df = normalize_crosstab(pd.DataFrame(extracted_table), **normalize_settings)\n",
    "        \n",
    "        # Rename column headers\n",
    "        if table_page_count == 1:\n",
    "            table_column_names = clean_names(normalized_df.columns)\n",
    "            normalized_df.columns = table_column_names\n",
    "        else:\n",
    "            if (len(normalized_df.columns) == len(all_tables[table_count-1].columns)):\n",
    "                normalized_df.columns = table_column_names\n",
    "            else:\n",
    "                normalized_df.columns = clean_names(normalized_df.columns)\n",
    "    \n",
    "        # Add page number, title, subtitle, and site name to the dataframe\n",
    "        normalized_df[\"page_number\"] = page_num\n",
    "        normalized_df[\"table_number\"] = table_number\n",
    "        normalized_df[\"title\"] = title\n",
    "        normalized_df[\"subtitle\"] = subtitle\n",
    "        normalized_df[\"dataset\"] = normalized_df['title'].str.replace('SUMMARY OF ANALYTICAL RESULTS FOR ', '')\n",
    "        normalized_df[\"site_name\"] = site_name\n",
    "        \n",
    "        # Concatenate the normalized table to the clean_tables DataFrame\n",
    "        all_tables[table_count-1] = pd.concat([all_tables[table_count-1], normalized_df])\n",
    "        \n",
    "        # Update the last table number\n",
    "        last_table_number = table_number\n",
    "\n",
    "# Close the PDF file\n",
    "pdf.close()\n",
    "\n",
    "fraw = f\"{output_dir}/{pdf_path.split('/')[-1].split('.')[0]}_raw\"\n",
    "\n",
    "# Save the list of tables to a pickle file\n",
    "with open(f\"{fraw}.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(all_tables, fout)\n",
    "    \n",
    "# Save each table to a worksheet in an Excel file using filename from pdf_path\n",
    "fout = f\"{fraw}.xlsx\"\n",
    "with pd.ExcelWriter(fout) as writer:\n",
    "    for i, table in enumerate(all_tables):\n",
    "        table.to_excel(writer, sheet_name=table_numbers[i], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file from last step\n",
    "with open(f\"{output_dir}/{pdf_path.split('/')[-1].split('.')[0]}_raw.pkl\", \"rb\") as fin:\n",
    "    all_tables = pickle.load(fin)\n",
    "\n",
    "# For Table \"A-9\", split conc_rl column into conc_rl, validator_qualifiers, and mdl using regex and remove conc_rl_qual_mdl column\n",
    "all_tables[8][[\"conc_rl\", \"validator_qualifier\", \"mdl\"]] = all_tables[8][\"conc_rl_qual_mdl\"].str.extract(r'^([\\d.]+)\\s*(.+)?\\s([\\d.]+)$')\n",
    "all_tables[8] = all_tables[8].drop(columns=[\"conc_rl_qual_mdl\"])\n",
    "\n",
    "# For Table \"A-10\", rename \"risk_based_action_limt_rsl\" to \"risk_based_action_limit_rsl\"\n",
    "all_tables[9] = all_tables[9].rename(columns={\"risk_based_action_limt_rsl\":\"risk_based_action_limit_rsl\"})\n",
    "\n",
    "# For Table \"A-11\", replace analyte \"MEtEhTylAbeLnSz e(µnge/L)\" with \"Ethylbenze\"\n",
    "all_tables[10][\"analyte\"] = all_tables[10][\"analyte\"].str.replace(\"MEtEhTylAbeLnSz e(µnge/L)\", \"Ethylbenzene\")\n",
    "\n",
    "# For Table \"A-15\", replace analyte \"Asbestos Analysis\" with \"ASBESTOS (%)\"\n",
    "all_tables[14][\"analyte\"] = all_tables[14][\"analyte\"].str.replace(\"Asbestos Analysis\", \"ASBESTOS (%)\")\n",
    "\n",
    "# For Table \"A-16\", combine the blank column with the \"client_id\" and drop the \"\" column\n",
    "all_tables[15][\"client_id\"] = all_tables[15][\"client_id\"] + \" \" + all_tables[15][\"\"]\n",
    "all_tables[15][\"client_id\"] = all_tables[15][\"client_id\"].str.strip()\n",
    "all_tables[15] = all_tables[15].drop(columns=[\"\"])\n",
    "\n",
    "# For Table \"A-16\", replace analyte \"Lead\" with \"Lead (mg/kg)\" and replace analyte \"Concentration\" with \"Lead\"\n",
    "all_tables[15][\"analyte\"] = all_tables[15][\"analyte\"].str.replace(\"Lead\", \"METALS (mg/kg)\")\n",
    "all_tables[15][\"analyte\"] = all_tables[15][\"analyte\"].str.replace(\"Concentration\", \"Lead\")\n",
    "\n",
    "# For Table \"A-18\", replace analyte \"(ng/g)\" with \"PCB CONGENERS (ng/g)\"\n",
    "all_tables[17][\"analyte\"] = all_tables[17][\"analyte\"].str.replace(\"(ng/g)\", \"PCB CONGENERS (ng/g)\")\n",
    "\n",
    "# Concatenate the list of tables into a single DataFrame\n",
    "clean_tables = pd.concat(all_tables)\n",
    "\n",
    "# Create analyte group and units columns from analyte column using regex (analyte_group is in ALL CAPS and usually precedes units in parentheses; e.g. METALS (mg/kg)) - IT CANNOT HAVE A CONCENTRATION\n",
    "clean_tables[\"analyte_group\"] = clean_tables[\"analyte\"].str.extract(r\"^([A-Z\\/]{2,}(?: [A-Z\\/]+)*)(?:\\s\\((?:SU|[a-z]+\\/[A-Za-z]+)\\)$)?\")\n",
    "clean_tables.loc[clean_tables[\"conc_rl\"] != \"\", \"analyte_group\"] = None\n",
    "clean_tables[\"units\"] = clean_tables[\"analyte\"].str.extract(r\"\\((SU|%|[^\\)]+\\/[A-Za-z]+)?\\)$\")\n",
    "clean_tables[\"units\"] = clean_tables[\"units\"].str.replace(\"µg/L\", \"ug/L\")\n",
    "\n",
    "# Group by table_number and fill down values for analyte group and units columns within each group\n",
    "clean_tables[\"analyte_group\"] = clean_tables.groupby(\"table_number\")[\"analyte_group\"].ffill()\n",
    "clean_tables[\"units\"] = clean_tables.groupby(\"table_number\")[\"units\"].ffill()\n",
    "\n",
    "# Manually set units to \"mg/kg\" for tables \"A-3\", \"A-4\", \"A-5\", \"A-6\"\n",
    "clean_tables.loc[clean_tables[\"table_number\"].isin([\"A-3\", \"A-4\", \"A-5\", \"A-6\"]), \"units\"] = \"mg/kg\"\n",
    "\n",
    "# Fill down missing locations\n",
    "clean_tables[\"location_id\"] = clean_tables.groupby(\"table_number\")[\"location_id\"].ffill()\n",
    "\n",
    "# Filter out rows where conc_rl is \"\"\n",
    "clean_tables = clean_tables[clean_tables[\"conc_rl\"] != \"\"]\n",
    "\n",
    "# Create column called \"detected\" which is False validator_qualifier contains \"U\" or conc_rl contains \"<\" or \"ND\" and True otherwise\n",
    "clean_tables[\"detected\"] = ~clean_tables[\"validator_qualifier\"].str.contains(\"U\", na=False) & ~clean_tables[\"conc_rl\"].str.contains(\"<|ND|NC|R|--\", na=True)\n",
    "\n",
    "# Add column for significant figures in conc_rl\n",
    "clean_tables[\"sigfigs\"] = 2\n",
    "\n",
    "# Remove non-numeric characters from conc_rl and convert conc_rl and mdl columns to numeric\n",
    "clean_tables[\"conc_rl\"] = clean_tables[\"conc_rl\"].str.replace(r\"[^0-9.]\", \"\", regex=True)\n",
    "clean_tables[\"conc_rl\"] = pd.to_numeric(clean_tables[\"conc_rl\"])\n",
    "clean_tables[\"mdl\"] = pd.to_numeric(clean_tables[\"mdl\"])\n",
    "\n",
    "# Remove all non-numeric characters from the level columns and convert all columns containing the text \"level\" or \"limit\" to numeric\n",
    "level_columns = [col for col in clean_tables.columns if \"level\" in col or \"limit\" in col]\n",
    "clean_tables[level_columns] = clean_tables[level_columns].replace(r\"[^0-9.]\", \"\", regex=True)\n",
    "clean_tables[level_columns] = clean_tables[level_columns].apply(pd.to_numeric)\n",
    "\n",
    "# Convert date_sampled to date (e.g. '29-Aug-2016' for table \"A-9\" and '8/20/2016' for all other tables)\n",
    "clean_tables.loc[clean_tables[\"table_number\"] == \"A-9\", \"date_sampled\"] = pd.to_datetime(clean_tables.loc[clean_tables[\"table_number\"] == \"A-9\", \"date_sampled\"], format=\"%d-%b-%Y\")\n",
    "clean_tables.loc[clean_tables[\"table_number\"] != \"A-9\", \"date_sampled\"] = pd.to_datetime(clean_tables.loc[clean_tables[\"table_number\"] != \"A-9\", \"date_sampled\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "# Extract table_order from table_number and page_order/result_order from index to preserve the order of the tables and results\n",
    "clean_tables[\"table_order\"] = clean_tables[\"table_number\"].str.extract(r'(\\d+)').astype(int)\n",
    "clean_tables[\"page_order\"] = clean_tables.index + 1\n",
    "clean_tables[\"result_order\"] = clean_tables.groupby(\"table_number\").cumcount() + 1\n",
    "\n",
    "# Reset the index\n",
    "clean_tables = clean_tables.reset_index(drop=True)\n",
    "\n",
    "# Re-order columns\n",
    "meta_columns = [\"table_order\", \"page_order\", \"result_order\", \"page_number\", \"table_number\", \"title\", \"subtitle\", \"site_name\", \"dataset\"]\n",
    "header_columns = [\"location_id\", \"client_id\", \"lab_id\", \"date_sampled\", \"matrix\", \"depth_ft_bgs\"]\n",
    "clean_tables = clean_tables[meta_columns + header_columns + (clean_tables.columns.difference(meta_columns+header_columns+level_columns)).tolist() + level_columns]\n",
    "\n",
    "# Save the clean tables to a pickle file and CSV using filename from pdf_path\n",
    "fout = f\"{output_dir}/{pdf_path.split('/')[-1].split('.')[0]}_clean\"\n",
    "clean_tables.to_pickle(f\"{fout}.pkl\")\n",
    "clean_tables.to_csv(f\"{fout}.csv\", index=False)\n",
    "clean_tables.to_excel(f\"{fout}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from pickle file\n",
    "clean_tables = pd.read_pickle(f\"{fout}.pkl\")\n",
    "\n",
    "# Database Connection\n",
    "engine = create_engine(os.getenv(\"DB_CONNECTION\"))\n",
    "\n",
    "# Write to PostgreSQL\n",
    "clean_tables.to_sql(os.getenv(\"DB_TABLE\"), engine, if_exists='replace', index=True)\n",
    "\n",
    "# Close connection\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
